{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db06ff3",
   "metadata": {},
   "source": [
    "# Code implementation\n",
    "### Author: Oscar Escudero Arnanz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82b485",
   "metadata": {},
   "source": [
    "## Transformers \"final version\"\n",
    "### Version: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Evaluating num_experts = 5\n",
      "\n",
      "Fold 1/5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model parameters that remain constant\n",
    "input_shape = (32, 32, 3)\n",
    "patch_size = 4\n",
    "num_patches = (input_shape[0] // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_layers = 4\n",
    "mlp_head_units = [128, 64]\n",
    "num_classes = 10\n",
    "dropout_rate = 0.1\n",
    "num_epochs = 50\n",
    "\n",
    "# Different numbers of experts to evaluate\n",
    "num_experts_list = [5, 6, 7, 8]\n",
    "\n",
    "# Load and preprocess CIFAR-10 data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainset, _ = torch.utils.data.random_split(trainset, [5000, len(trainset) - 5000])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testset, _ = torch.utils.data.random_split(testset, [1000, len(testset) - 1000])\n",
    "\n",
    "# Define the MoE (Mixture of Experts) class\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_experts, dropout_rate):\n",
    "        super(MoE, self).__init__()\n",
    "        self.experts = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        ) for _ in range(num_experts)])\n",
    "        self.gating_network = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_experts),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_values = self.gating_network(x)\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)\n",
    "        output = torch.sum(gate_values.unsqueeze(-2) * expert_outputs, dim=-1)\n",
    "        return output\n",
    "\n",
    "# Patch Embedding\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, num_patches, projection_dim, patch_dim):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        self.projection = nn.Linear(patch_dim, projection_dim)\n",
    "        self.position_embedding = nn.Embedding(num_patches, projection_dim)\n",
    "\n",
    "    def forward(self, patches):\n",
    "        positions = torch.arange(0, patches.size(1), device=patches.device).unsqueeze(0)\n",
    "        return self.projection(patches) + self.position_embedding(positions)\n",
    "\n",
    "# Transformer Encoder with MoE\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, projection_dim, num_heads, ff_dim, num_experts, dropout_rate):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(projection_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=projection_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.layer_norm2 = nn.LayerNorm(projection_dim)\n",
    "        self.moe = MoE(projection_dim, ff_dim, num_experts, dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm1 = self.layer_norm1(x)\n",
    "        attention_output, _ = self.attention(x_norm1, x_norm1, x_norm1)\n",
    "        x = x + self.dropout1(attention_output)\n",
    "        \n",
    "        x_norm2 = self.layer_norm2(x)\n",
    "        moe_output = self.moe(x_norm2)\n",
    "        return x + self.dropout2(moe_output)\n",
    "\n",
    "# Vision Transformer with MoE model\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, input_shape, patch_size, num_patches, projection_dim, num_heads, transformer_layers, mlp_head_units, num_classes, dropout_rate, num_experts):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        patch_dim = input_shape[2] * patch_size * patch_size\n",
    "\n",
    "        self.patch_embedding = PatchEmbedding(num_patches, projection_dim, patch_dim)\n",
    "\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerEncoder(projection_dim, num_heads, projection_dim, num_experts, dropout_rate)\n",
    "            for _ in range(transformer_layers)\n",
    "        ])\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "        self.mlp_head = MoE(projection_dim * num_patches, mlp_head_units[-1], num_experts, dropout_rate)\n",
    "        self.classifier = nn.Linear(mlp_head_units[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.extract_patches(x)\n",
    "        x = self.patch_embedding(x)\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.layer_norm(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.mlp_head(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def extract_patches(self, images):\n",
    "        batch_size = images.size(0)\n",
    "        patches = images.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.contiguous().view(batch_size, -1, self.patch_size * self.patch_size * images.size(1))\n",
    "        return patches\n",
    "\n",
    "# Configure the device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert data to tensors\n",
    "X_data = np.array([trainset[i][0].numpy() for i in range(len(trainset))])\n",
    "y_data = np.array([trainset[i][1] for i in range(len(trainset))])\n",
    "\n",
    "# Evaluate for each value of num_experts\n",
    "results = []\n",
    "\n",
    "for num_experts in num_experts_list:\n",
    "    print(f\"\\nEvaluating num_experts = {num_experts}\\n\")\n",
    "    \n",
    "    all_train_accuracies = []\n",
    "    all_val_accuracies = []\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_data)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        # Training and validation subsets for this fold\n",
    "        X_train_fold = torch.tensor(X_data[train_idx], dtype=torch.float32)\n",
    "        y_train_fold = torch.tensor(y_data[train_idx], dtype=torch.long)\n",
    "        X_val_fold = torch.tensor(X_data[val_idx], dtype=torch.float32)\n",
    "        y_val_fold = torch.tensor(y_data[val_idx], dtype=torch.long)\n",
    "        \n",
    "        # Create loaders\n",
    "        trainloader_fold = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train_fold, y_train_fold), batch_size=8, shuffle=True)\n",
    "        valloader_fold = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_val_fold, y_val_fold), batch_size=8, shuffle=False)\n",
    "        \n",
    "        # Initialize the model\n",
    "        model = VisionTransformer(\n",
    "            input_shape=input_shape,\n",
    "            patch_size=patch_size,\n",
    "            num_patches=num_patches,\n",
    "            projection_dim=projection_dim,\n",
    "            num_heads=num_heads,\n",
    "            transformer_layers=transformer_layers,\n",
    "            mlp_head_units=mlp_head_units,\n",
    "            num_classes=num_classes,\n",
    "            dropout_rate=dropout_rate,\n",
    "            num_experts=num_experts  # Evaluated hyperparameter\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Store losses and accuracies for plotting\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        # Train the model for this fold\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "\n",
    "            for i, (inputs, labels) in enumerate(trainloader_fold):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(trainloader_fold)\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            # Evaluate on the validation set for this fold\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in valloader_fold:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_val_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loss = running_val_loss / len(valloader_fold)\n",
    "            val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "        all_train_accuracies.append(train_accuracies)\n",
    "        all_val_accuracies.append(val_accuracies)\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_val_losses.append(val_losses)\n",
    "\n",
    "    # Average results for the evaluated number of experts\n",
    "    avg_train_accuracy = np.mean([acc[-1] for acc in all_train_accuracies])\n",
    "    avg_val_accuracy = np.mean([acc[-1] for acc in all_val_accuracies])\n",
    "    results.append((num_experts, avg_train_accuracy, avg_val_accuracy))\n",
    "    print(f\"num_experts = {num_experts}, Avg Train Accuracy: {avg_train_accuracy:.2f}%, Avg Val Accuracy: {avg_val_accuracy:.2f}%\")\n",
    "\n",
    "    # Plotting losses and accuracies for each fold\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, np.mean(all_train_losses, axis=0), label='Train loss')\n",
    "    plt.plot(epochs, np.mean(all_val_losses, axis=0), label='Validation loss')\n",
    "    plt.title(f'Loss for num_experts = {num_experts}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, np.mean(all_train_accuracies, axis=0), label='Train accuracy')\n",
    "    plt.plot(epochs, np.mean(all_val_accuracies, axis=0), label='Validation accuracy')\n",
    "    plt.title(f'Accuracy for num_experts = {num_experts}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Display results for all evaluated num_experts\n",
    "print(\"\\nFinal Results for different values of num_experts:\")\n",
    "for num_experts, train_acc, val_acc in results:\n",
    "    print(f\"num_experts = {num_experts}: Train Accuracy = {train_acc:.2f}%, Validation Accuracy = {val_acc:.2f}%\")\n",
    "\n",
    "# Select the best number of experts based on validation accuracy\n",
    "best_num_experts = max(results, key=lambda x: x[2])[0]\n",
    "print(f\"\\nBest number of experts based on validation accuracy: {best_num_experts}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "model = VisionTransformer(\n",
    "    input_shape=input_shape,\n",
    "    patch_size=patch_size,\n",
    "    num_patches=num_patches,\n",
    "    projection_dim=projection_dim,\n",
    "    num_heads=num_heads,\n",
    "    transformer_layers=transformer_layers,\n",
    "    mlp_head_units=mlp_head_units,\n",
    "    num_classes=num_classes,\n",
    "    dropout_rate=dropout_rate,\n",
    "    num_experts=best_num_experts  # Use the best number of experts\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"\\nAccuracy of the best model on the 1000 test images: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a835139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
